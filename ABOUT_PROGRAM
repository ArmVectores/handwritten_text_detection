# Word Detection Process Using YOLOv8 Model

This README outlines the process of detecting words in an image using the pre-trained YOLOv8 model from the ultralytics library. We will use the model to detect words in handwritten text.

## Required Dependencies

To work with the project, you only need to install 1 library

- arm_text_detection

You can install them via pip:

pip install ???????????


## Detector Initialization

from ultralytics import YOLO
from huggingface_hub import hf_hub_download

class Detector:
    def __init__(self):
        model_path = hf_hub_download(repo_id="armvectores/yolov8n_handwritten_text_detection", filename="best.pt")
        self.model = YOLO(model_path)


## Detecting Words in an Image

def detect(self, img_path):
    results = self.model.predict(source=img_path, conf=0.5)
    boxes = results[0].boxes.xyxy.cpu().numpy()
    return boxes


- We use model.predict with a conf parameter of 0.5, representing the confidence threshold, to get the bounding boxes of detected objects.
- We convert the coordinates of the bounding boxes into a NumPy array for easier processing.

## Extracting Words from Detected Boxes

from PIL import Image

def extract_words(self, img_path, boxes):
    image = Image.open(img_path)
    words_images = []
    for box in boxes:
        word_image = image.crop((box[0], box[1], box[2], box[3]))
        words_images.append(word_image)
    return words_images


- The extract_words method cuts and returns the regions of detected words from the original image.

## Loading and Detection

detector = Detector()
detector.init()

test_blank_path = hf_hub_download(repo_id="armvectores/yolov8n_handwritten_text_detection", filename="test_blank.png")
boxes = detector.detect(test_blank_path)
words_images = detector.extract_words(test_blank_path, boxes)


- After initializing the detector, we load the test image and perform detection.

## Visualization of Results

from matplotlib import pyplot as plt

print(boxes)
plt.figure(figsize=(15,10))
plt.imshow(plt.imread('detected/test_blank.png'))
plt.axis('off')
plt.show()

for i, word_img in enumerate(words_images, start=1):
    plt.figure(figsize=(200,10))
    plt.subplot(1, len(words_images), i)
    plt.imshow(word_img)
    plt.axis('off')
plt.show()


- First, we output the coordinates of the detected boxes.
- Then display the image with detected words.
- Finally, display each extracted word in a separate window.

This process demonstrates the operation of detection and extraction of words using YOLOv8 for analyzing handwritten text.
